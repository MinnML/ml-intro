{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Machine Learning\n",
    "\n",
    "* Instructor: [Saber Taghvaeeyan](https://www.linkedin.com/in/saber-taghvaeeyan-bb285739/)\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. Machine Learning Workflow\n",
    "1. Jupyter environment\n",
    "1. Download sample dataset\n",
    "1. Data pre-processing\n",
    "1. Training a model\n",
    "1. Testing the model\n",
    "1. What to try next\n",
    "\n",
    "We will end with time for questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning Workflow\n",
    "Following figure shows the the machine learning ecosystem at a high-level.\n",
    "\n",
    "![ml-eco](./doc/media/ml-eco.png)\n",
    "\n",
    "In this tutorial, our focus will be on the development phase.\n",
    "\n",
    "The development phase is outlined in the following figure.\n",
    "\n",
    "![ml-dev](./doc/media/ml-dev.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jupyter environment\n",
    "Let's start by a quick review of the jupyter environment and some simple tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for some simple commands.\n",
    "# Press ctrl+enter to execute a cell\n",
    "# Use shift+enter to execute a cell and move on to the next cell\n",
    "a = 1\n",
    "b = ...\n",
    "\n",
    "# Print the sum: a+b\n",
    "print(...)\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download sample dataset\n",
    "We will download a sample data set. The dataset we will be using is \"Appliances Energy Prediction Dataset\".\n",
    "\n",
    "Here is more information about his data set.\n",
    "https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "| Name | Description | Units |\n",
    "| ---      |  ------  |---------:|\n",
    "| date   | year-month-day   | hour:minute:second   |\n",
    "| Appliances   | energy use | Wh |\n",
    "| lights | energy use of light fixtures in the house | Wh |\n",
    "| T1 | temperature in kitchen area | C | \n",
    "| RH_1 | humidity in kitchen area | % | \n",
    "| T2 | Temperature in living room area | C |\n",
    "| RH_2 | Humidity in living room area | % | \n",
    "| T3 | Temperature in laundry room area | C |\n",
    "| RH_3 | Humidity in laundry room area | % |\n",
    "| T4 | Temperature in office room | C |\n",
    "| RH_4 | Humidity in office room | C |\n",
    "| T5 | Temperature in bathroom | C |\n",
    "| RH_5 | Humidity in bathroom | % |\n",
    "| T6 | Temperature outside the building (north side) | C |\n",
    "| RH_6 | Humidity outside the building (north side) | % |\n",
    "| T7 | Temperature in ironing room | C |\n",
    "| RH_7 | Humidity in ironing room | % |\n",
    "|T8 | Temperature in teenager room 2 | C |\n",
    "| RH_8 | Humidity in teenager room 2 | % |\n",
    "| T9 | Temperature in parents room | C |\n",
    "| RH_9 | Humidity in parents room | % |\n",
    "| To | Temperature outside (from Chievres weather station) | C |\n",
    "| Press_mm_hg | Pressure (from Chievres weather station) | mm Hg | \n",
    "| RH_out | Humidity outside (from Chievres weather station) | % |\n",
    "| Windspeed | Wind speed (from Chievres weather station) | m/s |\n",
    "| Visibility | Visibility (from Chievres weather station) | km |\n",
    "| Tdewpoint | Tdewpoint (from Chievres weather station) | Â°C | \n",
    "| rv1 | Random variable 1 | nondimensional | \n",
    "| rv2 | Random variable 2 | nondimensional | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Download the data as a DataFrame \n",
    "We can download the data directly from a web address using Pandas and put it into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>32.1</td>\n",
       "      <td>101.0</td>\n",
       "      <td>157</td>\n",
       "      <td>93.2</td>\n",
       "      <td>38.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.8598</td>\n",
       "      <td>87</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>21.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>183</td>\n",
       "      <td>103.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.8918</td>\n",
       "      <td>69</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>2</td>\n",
       "      <td>30.5</td>\n",
       "      <td>93.0</td>\n",
       "      <td>156</td>\n",
       "      <td>93.6</td>\n",
       "      <td>41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.6728</td>\n",
       "      <td>85</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>25.3</td>\n",
       "      <td>84.0</td>\n",
       "      <td>198</td>\n",
       "      <td>131.4</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.8903</td>\n",
       "      <td>89</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>192</td>\n",
       "      <td>125.4</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2905</td>\n",
       "      <td>80</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   BMI     BP   S1     S2    S3   S4      S5  S6    Y\n",
       "0   59    2  32.1  101.0  157   93.2  38.0  4.0  4.8598  87  151\n",
       "1   48    1  21.6   87.0  183  103.2  70.0  3.0  3.8918  69   75\n",
       "2   72    2  30.5   93.0  156   93.6  41.0  4.0  4.6728  85  141\n",
       "3   24    1  25.3   84.0  198  131.4  40.0  5.0  4.8903  89  206\n",
       "4   50    1  23.0  101.0  192  125.4  52.0  4.0  4.2905  80  135"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's get a sample dataset as a pandas dataframe\n",
    "df = pd.read_csv(\"energydata_complete.csv\")\n",
    "\n",
    "# Alternatively, we can directly download it from the web\n",
    "# df = pd.read_csv(\"https://github.com/LuisM78/Appliances-energy-prediction-data/raw/master/energydata_complete.csv\")\n",
    "\n",
    "# Print a few rows of the data, complete the following line:\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Get some information about the dataset\n",
    "We can leverage some of the internal *methods* of a DataFrame to gain more insight about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples do we have in this data set? Complete the following line\n",
    "print('Total number of samples: ', ...)\n",
    "print('')\n",
    "\n",
    "# Get dataset initial stats\n",
    "print(\"Dataset stats: \")\n",
    "print(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Visualize the data\n",
    "We can use `matplotlib` module to plot and visualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's visualize some of the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 1000\n",
    "feature_name = \"T9\"\n",
    "target_name = \"T2\"\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(df[feature_name].values[:n_samples], 'b-')\n",
    "ax2.plot(df[target_name].values[:n_samples], 'g-')\n",
    "ax1.set_xlabel('Samples')\n",
    "ax1.set_ylabel(feature_name, color='b')\n",
    "ax2.set_ylabel(target_name, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data pre-processing\n",
    "Most of the time, the data needs to be *prepared* to be used for developing machine learning models. We go over some of the basic steps in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create input and output\n",
    "We should extract the inputs (i.e. *data*) and outputs (i.e. *target*) from the dataframe. We will use the living room temperature as the target. We will use a subset of all the available features to speed up training.\n",
    "We will also exclude some of other temperatures as they may be very correlated with the living room temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\"lights\", # energy use of light fixtures in the house in Wh\n",
    "                   \"T4\", # Temperature in office room, in Celsius\n",
    "                   \"T6\", # Temperature outside the building (north side), in Celsius\n",
    "                   \"T7\", # Temperature in ironing room , in Celsius\n",
    "                   \"T8\", # Temperature in teenager room 2, in Celsius\n",
    "                   \"T9\", # Temperature in parents room, in Celsius\n",
    "                   \"T_out\", # Temperature outside (from Chievres weather station), in Celsius\n",
    "                   \"Press_mm_hg\", # (from Chievres weather station), in mm Hg\n",
    "                   \"RH_out\", # Humidity outside (from Chievres weather station), in %\n",
    "                   \"Windspeed\", # Windspeed (from Chievres weather station), in m/s\n",
    "                   \"Visibility\", # Visibility (from Chievres weather station), in km\n",
    "                   \"Tdewpoint\" # Dew point (from Chievres weather station), Â°C\n",
    "                  ]\n",
    "target_name = \"T2\"\n",
    "\n",
    "# Create a new dataframe with our desired columns\n",
    "col_names = features_to_use + [target_name]\n",
    "df_ml = df...\n",
    "\n",
    "# Check the stats of the new dataframe\n",
    "df_ml..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much data is missing for each column?\n",
    "df_stat = df.describe()\n",
    "df_stat.loc[\"count\"]/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "\n",
    "We have missing values in our dataset. There are several options we can consider:\n",
    "1) Remove missing values from our dataset.\n",
    "2) Fill in missing values with information from the individual columns, for example mean. (**Univariate feature imputation**)\n",
    "4) Fill in the missing values with information from other columns (**Multivariate feature imputation**).\n",
    "5) Use ML algorithms that can handle missing values, like `RandomForestRegressor`.\n",
    "\n",
    "Each method has its pros and cons. We will show a demo of options 1 and 3 in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that have missing values\n",
    "df_ml_clean = df_ml...\n",
    "\n",
    "# Check how much data we have lost.\n",
    "ratio = 100*(1 - df_ml_clean.shape[0]/df_ml.shape[0])\n",
    "print(f\"Percent of samples removed: {ratio: 0.3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling Missing Values\n",
    "\n",
    "If the above percentage is small, we can move on. But if it is significant, it is better to try one of the other methods for handling missing data.\n",
    "\n",
    "Next, we will show how to use MICE as a multivariate feature imputation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# Create an instance of the Imputer to use\n",
    "imp = IterativeImputer(...)\n",
    "# Fit imputer\n",
    "imp.fit(...)\n",
    "# Transform data using the fitter imputer to fill in the missing values\n",
    "clean_data = imp.transform(...)\n",
    "# Create a new dataframe with imputed data\n",
    "df_ml_clean = pd.DataFrame(columns=df_ml.columns, data=clean_data)\n",
    "\n",
    "# Check how much data we have lost.\n",
    "ratio = 100*(1 - df_ml_clean.shape[0]/df_ml.shape[0])\n",
    "print(f\"Percent of samples removed: {ratio: 0.3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handling missing values\n",
    "\n",
    "Now that we have discussed handling missing data, we will create input (data) and output (target) for our model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input data\n",
    "data = df_ml_clean[features_to_use]\n",
    "# Create target data\n",
    "target = df_ml_clean[target_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Split the data into train, test, validation\n",
    "For training a model and evaluating the performance, we devide the model into train, validation, and test sets. \n",
    "\n",
    "We will use the training and validation set to design the architecture, train the model, and optimize the hyperparameters. Then use the test set to report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Scikit-learn data splitting functions, complete the following line\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Determine train test splits\n",
    "test_ratio = ...\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(..., ..., test_size=..., shuffle=..., random_state=0)\n",
    "\n",
    "# Split the training data into training and validation\n",
    "x_trn, x_vld, y_trn, y_vld = train_test_split(..., ..., test_size=..., shuffle=..., random_state=0)\n",
    "\n",
    "# Print how many samples we have in each set, complete the following lines\n",
    "print(\"Number of samples in the training set: \", x_trn...)\n",
    "print(\"Number of samples in the validation set: \", x_vld...)\n",
    "print(\"Number of samples in the test set: \", x_tst...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Normalize the Data\n",
    "\n",
    "Most of the time, we should \\\"prepare\\\" our data and make it ready for model development. The preperation might include \n",
    "- proper formatting\n",
    "- handling missing data\n",
    "- converting categorical to numerical values\n",
    "- normalization\n",
    "\n",
    "Here, we only need to normalize the data since the other items are not applicable or have been addressed. Can you explain why we need to normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data, complete the following lines\n",
    "mean = x_trn...\n",
    "std = x_trn...\n",
    "x_trn = (x_trn - ...)/...\n",
    "x_vld = (x_vld - ...)/...\n",
    "x_tst = (x_tst - ...)/..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a model\n",
    "Now that we have prepared the data and split it into train, validation, and test sets, we can train ML models.\n",
    "\n",
    "Several different models are available from scikit-learn. We will start with a basic linear regression model. But, we will also look at other regressors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requried packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ...\n",
    "\n",
    "# Create an instance of the model, complete the following line\n",
    "regr = ...\n",
    "\n",
    "# Train the model, complete the following line\n",
    "regr.fit(..., ...)\n",
    "\n",
    "# Calculate the training error and print, completet the following lines\n",
    "y_trn_prd = regr.predict(...)\n",
    "trn_error = ...\n",
    "print(\"Training Error: {:.3f} \\n\".format(...))\n",
    "\n",
    "# Calculate the validation error, complete the following lines\n",
    "y_vld_prd = regr.predict(...)\n",
    "vld_error = ...\n",
    "print(\"Validation Error: {:.3f} \\n\".format(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing the model\n",
    "Once we have trained the model, and have finalized the parameters, we can see how it performs on out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we we have decided on the parameters, we can print the test error\n",
    "y_tst_prd = regr.predict(...)\n",
    "tst_error = np.mean(np.abs(y_tst - y_tst_prd))\n",
    "print(\"Test Error: {:.3f}\".format(tst_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediciton on a new data sample\n",
    "target_prd = regr.predict((data-mean)/std)\n",
    "samples_to_plot = 1000\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(target[:samples_to_plot], label='Target')\n",
    "plt.plot(target_prd[:samples_to_plot], \"--\", label='Target Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also take a look at the feature_importance. It basically shows how much each feature contributes to the final\n",
    "# prediction. \n",
    "feature_imp_df = pd.DataFrame(data={\"Name\": ..., \"Importance\": ...})\n",
    "display(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What to try next\n",
    "You can read about the following topics if you like to further pursue this topic:\n",
    "- Explore the data and check for missing values\n",
    "- Try the model without normalization and see if it affects the result\n",
    "- Read about and try other types of regressors in scikitlearn (`SVR`, `GradientBoostingRegressor`, `ExtraTreesRegressor`)\n",
    "- Read and try neural network based approaches (`ANN`, `RNN`, `CNN`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
