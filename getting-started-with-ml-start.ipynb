{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Machine Learning\n",
    "\n",
    "* Instructor: [Saber Taghvaeeyan](https://www.linkedin.com/in/saber-taghvaeeyan-bb285739/)\n",
    "\n",
    "## Agenda\n",
    "\n",
    "1. Machine Learning Workflow\n",
    "1. Jupyter environment\n",
    "1. Download sample dataset\n",
    "1. Data pre-processing\n",
    "1. Training a model\n",
    "1. Testing the model\n",
    "1. What to try next\n",
    "\n",
    "We will end with time for questions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning Workflow\n",
    "Following figure shows the the machine learning ecosystem at a high-level.\n",
    "\n",
    "![ml-eco](./doc/media/ml-eco.png)\n",
    "\n",
    "In this tutorial, our focus will be on the development phase.\n",
    "\n",
    "The development phase is outlined in the following figure.\n",
    "\n",
    "![ml-dev](./doc/media/ml-dev.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Jupyter environment\n",
    "Let's start by a quick review of the jupyter environment and some simple tricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for some simple commands.\n",
    "# Press ctrl+enter to execute a cell\n",
    "# Use shift+enter to execute a cell and move on to the next cell\n",
    "a = 1\n",
    "b = ...\n",
    "\n",
    "# Print the sum: a+b\n",
    "print(...)\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download sample dataset\n",
    "We will download a sample data set. The dataset we will be using is \"Appliances Energy Prediction Dataset\".\n",
    "\n",
    "Here is more information about his data set.\n",
    "https://archive.ics.uci.edu/ml/datasets/Appliances+energy+prediction\n",
    "\n",
    "**Attribute Information:**\n",
    "\n",
    "| Name | Description | Units |\n",
    "| ---      |  ------  |---------:|\n",
    "| date   | year-month-day   | hour:minute:second   |\n",
    "| Appliances   | energy use | Wh |\n",
    "| lights | energy use of light fixtures in the house | Wh |\n",
    "| T1 | temperature in kitchen area | C | \n",
    "| RH_1 | humidity in kitchen area | % | \n",
    "| T2 | Temperature in living room area | C |\n",
    "| RH_2 | Humidity in living room area | % | \n",
    "| T3 | Temperature in laundry room area | C |\n",
    "| RH_3 | Humidity in laundry room area | % |\n",
    "| T4 | Temperature in office room | C |\n",
    "| RH_4 | Humidity in office room | C |\n",
    "| T5 | Temperature in bathroom | C |\n",
    "| RH_5 | Humidity in bathroom | % |\n",
    "| T6 | Temperature outside the building (north side) | C |\n",
    "| RH_6 | Humidity outside the building (north side) | % |\n",
    "| T7 | Temperature in ironing room | C |\n",
    "| RH_7 | Humidity in ironing room | % |\n",
    "|T8 | Temperature in teenager room 2 | C |\n",
    "| RH_8 | Humidity in teenager room 2 | % |\n",
    "| T9 | Temperature in parents room | C |\n",
    "| RH_9 | Humidity in parents room | % |\n",
    "| To | Temperature outside (from Chievres weather station) | C |\n",
    "| Press_mm_hg | Pressure (from Chievres weather station) | mm Hg | \n",
    "| RH_out | Humidity outside (from Chievres weather station) | % |\n",
    "| Windspeed | Wind speed (from Chievres weather station) | m/s |\n",
    "| Visibility | Visibility (from Chievres weather station) | km |\n",
    "| Tdewpoint | Tdewpoint (from Chievres weather station) | Â°C | \n",
    "| rv1 | Random variable 1 | nondimensional | \n",
    "| rv2 | Random variable 2 | nondimensional | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Download the data as a DataFrame \n",
    "We can download the data directly from a web address using Pandas and put it into a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Let's get a sample dataset as a pandas dataframe\n",
    "df = pd.read_csv(\"energydata_complete.csv\")\n",
    "\n",
    "# Alternatively, we can directly download it from the web\n",
    "# df = pd.read_csv(\"https://github.com/LuisM78/Appliances-energy-prediction-data/raw/master/energydata_complete.csv\")\n",
    "\n",
    "# Print a few rows of the data, complete the following line:\n",
    "df..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Get some information about the dataset\n",
    "We can leverage some of the internal *methods* of a DataFrame to gain more insight about our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples do we have in this data set? Complete the following line\n",
    "print('Total number of samples: ', ...)\n",
    "print('')\n",
    "\n",
    "# Get dataset initial stats\n",
    "print(\"Dataset stats: \")\n",
    "print(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Visualize the data\n",
    "We can use `matplotlib` module to plot and visualize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's visualize some of the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 1000\n",
    "feature_name = \"T9\"\n",
    "target_name = \"T2\"\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(df[feature_name].values[:n_samples], 'b-')\n",
    "ax2.plot(df[target_name].values[:n_samples], 'g-')\n",
    "ax1.set_xlabel('Samples')\n",
    "ax1.set_ylabel(feature_name, color='b')\n",
    "ax2.set_ylabel(target_name, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data pre-processing\n",
    "Most of the time, the data needs to be *prepared* to be used for developing machine learning models. We go over some of the basic steps in this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Create input and output\n",
    "We should extract the inputs (i.e. *data*) and outputs (i.e. *target*) from the dataframe. We will use the living room temperature as the target. We will use a subset of all the available features to speed up training.\n",
    "We will also exclude some of other temperatures as they may be very correlated with the living room temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = [\"lights\", # energy use of light fixtures in the house in Wh\n",
    "                   \"T4\", # Temperature in office room, in Celsius\n",
    "                   \"T6\", # Temperature outside the building (north side), in Celsius\n",
    "                   \"T7\", # Temperature in ironing room , in Celsius\n",
    "                   \"T8\", # Temperature in teenager room 2, in Celsius\n",
    "                   \"T9\", # Temperature in parents room, in Celsius\n",
    "                   \"T_out\", # Temperature outside (from Chievres weather station), in Celsius\n",
    "                   \"Press_mm_hg\", # (from Chievres weather station), in mm Hg\n",
    "                   \"RH_out\", # Humidity outside (from Chievres weather station), in %\n",
    "                   \"Windspeed\", # Windspeed (from Chievres weather station), in m/s\n",
    "                   \"Visibility\", # Visibility (from Chievres weather station), in km\n",
    "                   \"Tdewpoint\" # Dew point (from Chievres weather station), Â°C\n",
    "                  ]\n",
    "target_name = \"T2\"\n",
    "\n",
    "data = df[...]\n",
    "target = df[...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Split the data into train, test, validation\n",
    "For training a model and evaluating the performance, we devide the model into train, validation, and test sets. \n",
    "\n",
    "We will use the training and validation set to design the architecture, train the model, and optimize the hyperparameters. Then use the test set to report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Scikit-learn data splitting functions, complete the following line\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Determine train test splits\n",
    "test_ratio = ...\n",
    "\n",
    "# Split the data into training and testing\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(..., ..., test_size=..., shuffle=..., random_state=0)\n",
    "\n",
    "# Split the training data into training and validation\n",
    "x_trn, x_vld, y_trn, y_vld = train_test_split(..., ..., test_size=..., shuffle=..., random_state=0)\n",
    "\n",
    "# Print how many samples we have in each set, complete the following lines\n",
    "print(\"Number of samples in the training set: \", x_trn...)\n",
    "print(\"Number of samples in the validation set: \", x_vld...)\n",
    "print(\"Number of samples in the test set: \", x_tst...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Normalize the Data\n",
    "\n",
    "Most of the time, we should \\\"prepare\\\" our data and make it ready for model development. The preperation might include \n",
    "- proper formatting\n",
    "- handling missing data\n",
    "- converting categorical to numerical values\n",
    "- normalization\n",
    "\n",
    "Here, we only need to normalize the data since the other items are not applicable or have been addressed. Can you explain why we need to normalize the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data, complete the following lines\n",
    "mean = x_trn...\n",
    "std = x_trn...\n",
    "x_trn = (x_trn - ...)/...\n",
    "x_vld = (x_vld - ...)/...\n",
    "x_tst = (x_tst - ...)/..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training a model\n",
    "Now that we have prepared the data and split it into train, validation, and test sets, we can train ML models.\n",
    "\n",
    "Several different models are available from scikit-learn. We will start with a basic linear regression model. But, we will also look at other regressors as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import requried packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ...\n",
    "\n",
    "# Create an instance of the model, complete the following line\n",
    "regr = ...\n",
    "\n",
    "# Train the model, complete the following line\n",
    "regr.fit(..., ...)\n",
    "\n",
    "# Calculate the training error and print, completet the following lines\n",
    "y_trn_prd = regr.predict(...)\n",
    "trn_error = ...\n",
    "print(\"Training Error: {:.3f} \\n\".format(...))\n",
    "\n",
    "# Calculate the validation error, complete the following lines\n",
    "y_vld_prd = regr.predict(...)\n",
    "vld_error = ...\n",
    "print(\"Validation Error: {:.3f} \\n\".format(...))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing the model\n",
    "Once we have trained the model, and have finalized the parameters, we can see how it performs on out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once we we have decided on the parameters, we can print the test error\n",
    "y_tst_prd = regr.predict(...)\n",
    "tst_error = np.mean(np.abs(y_tst - y_tst_prd))\n",
    "print(\"Test Error: {:.3f}\".format(tst_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making prediciton on a new data sample\n",
    "target_prd = regr.predict((data-mean)/std)\n",
    "samples_to_plot = 1000\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(target[:samples_to_plot], label='Target')\n",
    "plt.plot(target_prd[:samples_to_plot], \"--\", label='Target Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also take a look at the feature_importance. It basically shows how much each feature contributes to the final\n",
    "# prediction. \n",
    "feature_imp_df = pd.DataFrame(data={\"Name\": ..., \"Importance\": ...})\n",
    "display(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. What to try next\n",
    "You can read about the following topics if you like to further pursue this topic:\n",
    "- Explore the data and check for missing values\n",
    "- Try the model without normalization and see if it affects the result\n",
    "- Read about and try other types of regressors in scikitlearn (`SVR`, `GradientBoostingRegressor`, `ExtraTreesRegressor`)\n",
    "- Read and try neural network based approaches (`ANN`, `RNN`, `CNN`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
